<!DOCTYPE html>


<html lang="zh-CN">


<head>
  <meta charset="utf-8" />
    
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
  <title>
    Haar特征描述算子-人脸检测 |  言念君子
  </title>
  <meta name="generator" content="hexo-theme-ayer">
  
  <link rel="shortcut icon" href="/favicon.ico" />
  
  
<link rel="stylesheet" href="/dist/main.css">

  
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/css/remixicon.min.css">

  
<link rel="stylesheet" href="/css/custom.css">

  
  
<script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script>

  
  

  

</head>

</html>

<body>
  <div id="app">
    
      
      <canvas width="1777" height="841"
        style="position: fixed; left: 0px; top: 0px; z-index: 99999; pointer-events: none;"></canvas>
      
    <main class="content on">
      <section class="outer">
  <article
  id="post-Haar特征描述算子-人脸检测"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h1 class="article-title sea-center" style="border-left:0" itemprop="name">
  Haar特征描述算子-人脸检测
</h1>
 

    </header>
     
    <div class="article-meta">
      <a href="/posts/7e50584a.html" class="article-date">
  <time datetime="2020-08-03T11:51:01.794Z" itemprop="datePublished">2020-08-03</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/CV/">CV</a>
  </div>
  
<div class="word_count">
    <span class="post-time">
        <span class="post-meta-item-icon">
            <i class="ri-quill-pen-line"></i>
            <span class="post-meta-item-text"> 字数统计:</span>
            <span class="post-count">5.2k</span>
        </span>
    </span>

    <span class="post-time">
        &nbsp; | &nbsp;
        <span class="post-meta-item-icon">
            <i class="ri-book-open-line"></i>
            <span class="post-meta-item-text"> 阅读时长≈</span>
            <span class="post-count">20 分钟</span>
        </span>
    </span>
</div>
 
    </div>
      
    <div class="tocbot"></div>




  
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="人脸检测例子"><a href="#人脸检测例子" class="headerlink" title="人脸检测例子"></a>人脸检测例子</h1><h2 id="人脸检测"><a href="#人脸检测" class="headerlink" title="人脸检测"></a>人脸检测</h2><p>在开始介绍Haar特征描述算子之前，为了便于理解，我们直接看具体怎么通过opencv调用训练好的haar模型，从而实现人脸识别。首先Mark一下一些已经训练好的haar的模型，可以直接下载，里面包含了多种人类特征检测的训练模型，包括脸、身体、眼睛、笑脸等，链接<a href="https://github.com/opencv/opencv/tree/master/data/haarcascades" target="_blank" rel="noopener">戳我</a></p>
<p>我们打开的github链接长这样：</p>
<p><img src="/posts/CV/haar1.png" alt></p>
<p>我们下载其中一个haarcascade_frontalface_default.xml作为示例（点Raw后下载网页）。然后我们导入待识别图：</p>
<p><img src="/posts/CV/4.jpg" alt></p>
<p>执行以下代码，即可获得人脸检测的结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">img = cv2.imread(<span class="string">"Pic/1.jpg"</span>)</span><br><span class="line"></span><br><span class="line">face_engine = cv2.CascadeClassifier(cv2.data.haarcascades+<span class="string">'haarcascade_frontalface_default.xml'</span>)</span><br><span class="line"></span><br><span class="line">faces = face_engine.detectMultiScale(img,scaleFactor=<span class="number">1.3</span>,minNeighbors=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (x,y,w,h) <span class="keyword">in</span> faces:</span><br><span class="line">    img = cv2.rectangle(img,(x,y),(x+w,y+h),(<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>),<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">cv2.imshow(<span class="string">'img'</span>,img)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>
<p>检测结果不负众望：</p>
<p><img src="/posts/CV/reba.png" alt></p>
<p>我们留意到以上代码的face_engine步骤，其作用是导入人脸级联分类器引擎，’.xml’文件里包含训练出来的人脸特征。随后用人脸级联分类器引擎进行人脸识别，返回的faces为人脸坐标列表，1.3是放大比例，5是重复识别次数。</p>
<h2 id="人脸检测和人眼检测"><a href="#人脸检测和人眼检测" class="headerlink" title="人脸检测和人眼检测"></a>人脸检测和人眼检测</h2><p>我们也可以尝试前面xml文件中的人眼检测：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#导入opencv</span></span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line"><span class="comment"># 导入人脸级联分类器引擎，'.xml'文件里包含训练出来的人脸特征，cv2.data.haarcascades即为存放所有级联分类器模型文件的目录</span></span><br><span class="line">face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades+<span class="string">'haarcascade_frontalface_default.xml'</span>)</span><br><span class="line"><span class="comment"># 导入人眼级联分类器引擎吗，'.xml'文件里包含训练出来的人眼特征</span></span><br><span class="line">eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades+<span class="string">'haarcascade_eye.xml'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读入一张图片，引号里为图片的路径，需要你自己手动设置</span></span><br><span class="line">img = cv2.imread(<span class="string">'image3.png'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 用人脸级联分类器引擎进行人脸识别，返回的faces为人脸坐标列表，1.3是放大比例，5是重复识别次数</span></span><br><span class="line">faces = face_cascade.detectMultiScale(img, <span class="number">1.3</span>, <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对每一张脸，进行如下操作</span></span><br><span class="line"><span class="keyword">for</span> (x,y,w,h) <span class="keyword">in</span> faces:</span><br><span class="line">    <span class="comment"># 画出人脸框，蓝色（BGR色彩体系），画笔宽度为2</span></span><br><span class="line">    img = cv2.rectangle(img,(x,y),(x+w,y+h),(<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>),<span class="number">2</span>)</span><br><span class="line">    <span class="comment"># 框选出人脸区域，在人脸区域而不是全图中进行人眼检测，节省计算资源</span></span><br><span class="line">    face_area = img[y:y+h, x:x+w]</span><br><span class="line">    eyes = eye_cascade.detectMultiScale(face_area)</span><br><span class="line">    <span class="comment"># 用人眼级联分类器引擎在人脸区域进行人眼识别，返回的eyes为眼睛坐标列表</span></span><br><span class="line">    <span class="keyword">for</span> (ex,ey,ew,eh) <span class="keyword">in</span> eyes:</span><br><span class="line">        <span class="comment">#画出人眼框，绿色，画笔宽度为1</span></span><br><span class="line">        cv2.rectangle(face_area,(ex,ey),(ex+ew,ey+eh),(<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>),<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在"img2"窗口中展示效果图</span></span><br><span class="line">cv2.imshow(<span class="string">'img2'</span>,img)</span><br><span class="line"><span class="comment"># 监听键盘上任何按键，如有案件即退出并关闭窗口，并将图片保存为output.jpg</span></span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br><span class="line">cv2.destroyAllWindows()</span><br><span class="line">cv2.imwrite(<span class="string">'output.jpg'</span>,img)</span><br></pre></td></tr></table></figure>
<p>上面的代码最值得注意的就是face_area = img[y:y+h, x:x+w]，这一步会将人脸区域框出来，在其中执行人眼检测。同样对上图进行检测，结果如下：</p>
<p><img src="/posts/CV/output.jpg" alt></p>
<p>结果还行吧。</p>
<h2 id="调用电脑摄像头进行实时人脸识别和人眼识别"><a href="#调用电脑摄像头进行实时人脸识别和人眼识别" class="headerlink" title="调用电脑摄像头进行实时人脸识别和人眼识别"></a>调用电脑摄像头进行实时人脸识别和人眼识别</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line">face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades+<span class="string">'haarcascade_frontalface_default.xml'</span>)</span><br><span class="line"></span><br><span class="line">eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades+<span class="string">'haarcascade_eye.xml'</span>)</span><br><span class="line"><span class="comment"># 调用摄像头摄像头</span></span><br><span class="line">cap = cv2.VideoCapture(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span>(<span class="literal">True</span>):</span><br><span class="line">    <span class="comment"># 获取摄像头拍摄到的画面</span></span><br><span class="line">    ret, frame = cap.read()</span><br><span class="line">    faces = face_cascade.detectMultiScale(frame, <span class="number">1.3</span>, <span class="number">5</span>)</span><br><span class="line">    img = frame</span><br><span class="line">    <span class="keyword">for</span> (x,y,w,h) <span class="keyword">in</span> faces:</span><br><span class="line">    	<span class="comment"># 画出人脸框，蓝色，画笔宽度微</span></span><br><span class="line">        img = cv2.rectangle(img,(x,y),(x+w,y+h),(<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>),<span class="number">2</span>)</span><br><span class="line">    	<span class="comment"># 框选出人脸区域，在人脸区域而不是全图中进行人眼检测，节省计算资源</span></span><br><span class="line">        face_area = img[y:y+h, x:x+w]</span><br><span class="line">        eyes = eye_cascade.detectMultiScale(face_area)</span><br><span class="line">    	<span class="comment"># 用人眼级联分类器引擎在人脸区域进行人眼识别，返回的eyes为眼睛坐标列表</span></span><br><span class="line">        <span class="keyword">for</span> (ex,ey,ew,eh) <span class="keyword">in</span> eyes:</span><br><span class="line">            <span class="comment">#画出人眼框，绿色，画笔宽度为1</span></span><br><span class="line">            cv2.rectangle(face_area,(ex,ey),(ex+ew,ey+eh),(<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>),<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">	<span class="comment"># 实时展示效果画面</span></span><br><span class="line">    cv2.imshow(<span class="string">'frame2'</span>,img)</span><br><span class="line">    <span class="comment"># 每5毫秒监听一次键盘动作</span></span><br><span class="line">    <span class="keyword">if</span> cv2.waitKey(<span class="number">5</span>) &amp; <span class="number">0xFF</span> == ord(<span class="string">'q'</span>):</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 最后，关闭所有窗口</span></span><br><span class="line">cap.release()</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>
<p>以上我们都可以通过调整参数调整精度要求。</p>
<h1 id="Haar原理解析"><a href="#Haar原理解析" class="headerlink" title="Haar原理解析"></a>Haar原理解析</h1><h2 id="Haar特征"><a href="#Haar特征" class="headerlink" title="Haar特征"></a>Haar特征</h2><p>Haar特征包含三种：边缘特征、线性特征、中心特征和对角线特征。每种分类器都从图片中提取出对应的特征。有点类似于卷积神经网络中的卷积核，每个卷积核提取出对应的特征。</p>
<p>我们最基础的卷积核（划掉），哦不haar特征为下图中的Basic Haar Set：</p>
<p><img src="/posts/CV/haar2.jpg" alt></p>
<p>我们通常将Haar特征分为以下三类，我们根据名字就可以分辨出这三类的用途:</p>
<ul>
<li><p>第一类是边缘特征：<br><img src="/posts/CV/haar3.png" alt></p>
</li>
<li><p>第二类是线性特征：<br><img src="/posts/CV/haar4.png" alt></p>
</li>
<li><p>第三类是中心特征：<br><img src="/posts/CV/haar5.jpg" alt></p>
</li>
</ul>
<p>特征模板内有白色和黑色两种矩形，并定义该模板的特征值为白色矩形像素和减去黑色矩形像素和。Haar特征值反映了图像的灰度变化情况。</p>
<p>例如：脸部的一些特征能由矩形特征简单的描述，如：眼睛要比脸颊颜色要深，鼻梁两侧比鼻梁颜色要深，嘴巴比周围颜色要深等。但矩形特征只对一些简单的图形结构，如边缘、线段较敏感，所以只能描述特定走向（水平、垂直、对角）的结构。由于有时候人脸未必是定向的，可能是会有歪曲的，因此我们可以训练旋转一定角度的矩形特征来识别人脸。</p>
<p><img src="/posts/CV/haar6.png" alt></p>
<p>总而言之，Haar特征就是利用一些固定的特征来模拟人脸中的相关特征。</p>
<p>矩形特征可位于图像任意位置，大小也可以任意改变，所以矩形特征值是矩形模版类别、矩形位置和矩形大小这三个因素的函数。故类别、大小和位置的变化，使得很小的检测窗口含有非常多的矩形特征，如：在24*24像素大小的检测窗口内矩形特征数量可以达到16万个。这样就有两个问题需要解决了：</p>
<p>（1）如何快速计算那么多的特征？—-积分图大显神通；</p>
<p>（2）哪些矩形特征才是对分类器分类最有效的？—-如通过AdaBoost算法来训练。</p>
<h2 id="积分图构建"><a href="#积分图构建" class="headerlink" title="积分图构建"></a>积分图构建</h2><p>在一个图像窗口中，可以提取出大量的Haar矩形特征区域，如果在计算Haar特征值时，每次都遍历矩形特征区域，将会造成大量重复计算，严重浪费时间。积分图是一种快速计算矩形特征的方法，主要思想是将图像起始像素点到每一个像素点之间所形成的矩形区域的像素值的和，作为一个元素保存下来，即将原始图像转换为积分图(或者求和图)，当求某一矩形区域的像素和时，只需要索引矩形区域4个角点在积分图中的取值，进行普通的加减运算，即可求得Haar特征值，整个过程只需遍历一次图像，计算特征的时间复杂度为常数(O(1))(O(1))，可以大大提升计算效率。<br>积分图中元素的公式定义如下：</p>
<script type="math/tex; mode=display">ii(x,y) = \sum_{k\le x,l\le y}f(k,l)</script><p>上式含义是在$(x,y)$位置处，积分图中元素为原图像中对应像素左上角所有像素值之和，$ii(x,y)$表示一个积分图像。在具体实现时，可用下式进行迭代运算:</p>
<script type="math/tex; mode=display">s(x,y) = s(x,y-1)+i(x,y)</script><script type="math/tex; mode=display">ii(x,y) = ii(x-1,y)+s(x,y)</script><p>其中$s$是行方向的累加和，初始值$s(x,-1)=0,ii(-1,y)=0$，但这个公式不是很好（为什么？），一个比较好的替代是下面这个公式：</p>
<script type="math/tex; mode=display">ii(x,y) = ii(x-1,y)+ii(x,y-1)+f(x,y)-ii(i-1,j-1)</script><h2 id="计算Haar特征值"><a href="#计算Haar特征值" class="headerlink" title="计算Haar特征值"></a>计算Haar特征值</h2><h3 id="矩形特征"><a href="#矩形特征" class="headerlink" title="矩形特征"></a>矩形特征</h3><p>构建好积分图后，图像中任何矩形区域的像素值累加和都可以通过简单的加减运算快速得到，如下图所示，矩形区域D的像素和值计算公式如下：</p>
<p>$\operatorname{Sum}(D)=i i\left(x_{4}, y_{4}\right)-i i\left(x_{2}, y_{2}\right)-i i\left(x_{3}, y_{3}\right)+i i\left(x_{1}, y_{1}\right)$</p>
<p><img src="/posts/CV/haar7.png" alt></p>
<p>矩形区域求和示意图 在下图中，以水平向右为$x$轴正方向，垂直向下为$y$轴正方向，可定义积分图公式Summed Area Table$(S A T(x, y))$</p>
<script type="math/tex; mode=display">
S A T(x, y)=\Sigma_{x^{\prime} \leq x, y^{\prime} \leq y} i\left(x^{\prime}, y^{\prime}\right)</script><p>以及迭代求解式</p>
<script type="math/tex; mode=display">
\begin{array}{c}
S A T(x, y)=S A T(x, y-1)+S A T(x-1, y)-S A T(x-1, y-1)+I(x, y) \\
S A T(-1, y)=0, S A T(x,-1)=0
\end{array}</script><p>对于左上角坐标为$(x, y),$宽高为$(w, h)$的矩形区域$r(x, y, w, h, 0),$可利用积分图$S A T(x, y)$求取像素和值</p>
<script type="math/tex; mode=display">
\operatorname{RecSum}(r)=S A T(x+w-1, y+h-1)+S A T(x-1, y-1)-S A T(x+w-1, y-1)-S A T(x-1, y+h-1)</script><p><img src="/posts/CV/haar8.png" alt></p>
<h3 id="旋转矩形特征"><a href="#旋转矩形特征" class="headerlink" title="旋转矩形特征"></a>旋转矩形特征</h3><p>对于旋转矩形特征，相应的有$45$°倾斜积分图用于快速计算Haar特征值，如下图所示，倾斜积分图的定义为像素点左上角$45$°区域和左下角$45$°区域的像素和，公式表示如下：</p>
<script type="math/tex; mode=display">RSAT(x, y)=\Sigma_{x^{\prime} \leq x, x^{\prime} \leq x-\left|y-y^{\prime}\right|} i\left(x^{\prime}, y^{\prime}\right)</script><p>其递推公式计算如下：</p>
<script type="math/tex; mode=display">\begin{array}{c}
R S A T(x, y)=R S A T(x-1, y-1)+R S A T(x-1, y)-R S A T(x-2, y-1)+I(x, y) \\
R S A T(x, y)=R S A T(x, y)+R S A T(x-1, y+1)-R S A T(x-2, y) \\
\end{array}</script><p>其中$R S A T(-1, y)=R S A T(-2, y)=R S A T(x,-1)=0$</p>
<p>也可直接通过下式递归计算:</p>
<script type="math/tex; mode=display">R S A T(x, y)=R S A T(x-1, y-1)+R S A T(x+1, y-1)-R S A T(x, y-2)+I(x-1, y)+I(x, y)</script><p>以上3个积分图计算公式是等价的。</p>
<p>如下图所示，构建好倾斜积分图后，可快速计算倾斜矩形区域r$=\left(x, y, w, h, 45^{\circ}\right)$的像素和值</p>
<p><img src="/posts/CV/haar9.png" alt></p>
<script type="math/tex; mode=display">\operatorname{RecSum}(r)=R S A T(x+w, y+w)+R S A T(x-h, y+h)-R S A T(x, y)-R S A T(x+w-h, y+w+h)</script><h3 id="举个例子"><a href="#举个例子" class="headerlink" title="举个例子"></a>举个例子</h3><p>了解了特征值的计算之后，我们来看看不同的特征值的含义是什么。我们选取MIT人脸库中2706个大小为$20*20$的人脸正样本图像，计算如下图所示的Haar特征：</p>
<p><img src="/posts/CV/haar10.jpg" alt></p>
<p>左边对应的人眼区域，右边无具体意义。</p>
<p><img src="/posts/CV/harr11.png" alt></p>
<p>可以看到，图中2个不同Haar特征在同一组样本中具有不同的特征值分布，左边特征计算出的特征值基本都大于0（对样本的区分度大），而右边特征的特征值基本均匀分布于0两侧（对样本的区分度小）。所以，正是由于样本中Haar特征值分布不均匀，导致了不同Haar特征分类效果不同。显而易见，对正负样本区分度越大的特征分类效果越好，即红色曲线对应图中的的左边Haar特征分类效果好于右边Haar特征。</p>
<p>那么看到这里，应该理解了下面2个问题：</p>
<ol>
<li>在检测窗口通过平移+缩放可以产生一系列Haar特征，这些特征由于位置和大小不同，分类效果也不同；</li>
<li>通过计算Haar特征的特征值，可以有将图像矩阵映射为1维特征值，有效实现了降维。</li>
</ol>
<h2 id="Haar特征归一化"><a href="#Haar特征归一化" class="headerlink" title="Haar特征归一化"></a>Haar特征归一化</h2><p>从上图我们可以发现，仅仅一个$128$维大小的Haar特征计算出的特征值变化范围从$-2000~+6000$，跨度非常大。这种跨度大的特性不利于量化评定特征值，所以需要进行“归一化”，压缩特征值范围。假设当前检测窗口中的图像像素为$i(x,y)$，当前检测窗口为$w∗h$大小（例如上图中为2020大小），OpenCV采用如下方式“归一化”：</p>
<ol>
<li>计算检测窗口中图像的灰度值和灰度值平方和：$sum=\sum i(x,y)$</li>
</ol>
<script type="math/tex; mode=display">sq_{sum}=\sum i^2(x,y)</script><ol>
<li>计算平均值：</li>
</ol>
<script type="math/tex; mode=display">mean = \frac{sum}{w*h}</script><script type="math/tex; mode=display">sq_{mean}=\frac{sq_{sum}}{w*h}</script><ol>
<li><p>计算归一化因子：</p>
<script type="math/tex; mode=display">varNormFactor=\sqrt{sq_{mean}-mean^2}</script></li>
<li><p>归一化特征值：$normValue=\frac{featureValue}{varNormFactor}$之后使用归一化的特征值$normValue$与阈值对比。</p>
</li>
</ol>
<h2 id="级联"><a href="#级联" class="headerlink" title="级联"></a>级联</h2><h3 id="白话解释"><a href="#白话解释" class="headerlink" title="白话解释"></a>白话解释</h3><p>这里我们并不打算详细阐述AdaBoost的完整工作机制以及一些更细节的部分，我们将从宏观层面来看级联的流程。</p>
<p><strong>基于Haar特征的cascade级联分类器</strong>是Paul Viola和 Michael Jone在2001年的论文”Rapid Object Detection using a Boosted Cascade of Simple Features”中提出的一种有效的物体检测方法。</p>
<p><strong>Cascade级联分类器的训练方法：Adaboost</strong></p>
<p>级联分类器的函数是通过大量带人脸和不带人脸的图片通过机器学习得到的。对于人脸识别来说，需要几万个特征，通过机器学习找出人脸分类效果最好、错误率最小的特征。训练开始时，所有训练集中的图片具有相同的权重，对于被分类错误的图片，提升权重，重新计算出新的错误率和新的权重。直到错误率或迭代次数达到要求。这种方法叫做Adaboost，在Opencv中可以直接调用级联分类器函数。</p>
<p><strong>将弱分类器聚合成强分类器</strong></p>
<p>最终的分类器是这些弱分类器的加权和。之所以称之为弱分类器是因为每个分类器不能单独分类图片，但是将他们聚集起来就形成了强分类器。论文表明，只需要200个特征的分类器在检测中的精确度达到了95%。最终的分类器大约有6000个特征。(将超过160000个特征减小到6000个，这是非常大的进步了）。</p>
<p><strong>级联的含义：需过五关斩六将才能被提取出来</strong></p>
<p>事实上，一张图片绝大部分的区域都不是人脸。如果对一张图片的每个角落都提取6000个特征，将会浪费巨量的计算资源。</p>
<p>如果能找到一个简单的方法能够检测某个窗口是不是人脸区域，如果该窗口不是人脸区域，那么就只看一眼便直接跳过，也就不用进行后续处理了，这样就能集中精力判别那些可能是人脸的区域。 为此，有人引入了Cascade 分类器。它不是将6000个特征都用在一个窗口，而是将特征分为不同的阶段，然后一个阶段一个阶段的应用这些特征(通常情况下，前几个阶段只有很少量的特征)。如果窗口在第一个阶段就检测失败了，那么就直接舍弃它，无需考虑剩下的特征。如果检测通过，则考虑第二阶段的特征并继续处理。如果所有阶段的都通过了，那么这个窗口就是人脸区域。 作者的检测器将6000+的特征分为了38个阶段，前五个阶段分别有1，10，25，25，50个特征(前文图中提到的识别眼睛和鼻梁的两个特征实际上是Adaboost中得到的最好的两个特征)。根据作者所述，平均每个子窗口只需要使用6000+个特征中的10个左右。</p>
<p>简单地说，在进行人脸检测的过程中，需要使用一个强分类器，且其由多个弱分类器组成。那么其中的每个弱分类器都只包含一个Haar特征。每个分类器都将确定一个阈值，如果某区域的处理差值小于该阈值，则被归为负类，反之则进行下一级的弱分类，最终经过多个弱分类器后，可完成检测。其分类过程如下图所示：</p>
<p><img src="/posts/CV/haar13.png" alt></p>
<h3 id="举个例子-1"><a href="#举个例子-1" class="headerlink" title="举个例子"></a>举个例子</h3><p><img src="/posts/CV/haar12.png" alt></p>
<ol>
<li>首先，对于一幅图像，它可能存在K个面部特征，假设这些面部特征可以用来区分眼睛、眉毛、鼻子、嘴等特征。</li>
<li>确定一些超参数，如滑动窗口的大小，及窗口的移动步长。窗口从上往下，从左向右地滑动。在滑动的过程中，每次都可以计算出一个数值$K$。</li>
<li>滑动结束时，将得到的特征值进行排序，并选取一个最佳特征值（最优阈值），使得在该特征值下，对于该特征而言，样本的加权错误率最低。这样就训练出了一个弱分类器。</li>
<li>因为面部特征的不同，我们将采用不同的滑动窗口进行特征提取。所以根据不同的窗口识别不同的特征，进而训练出了不同的弱分类器。</li>
<li>对于每个弱分类器都将计算它的错误率，选择错误率最低的K个弱分类器，组合成强分类器。</li>
<li>一组样本投入强分类器后，在每个渐进的阶段，分类器逐渐在较少的图像窗口上使用更多的特征（负类被丢弃）。如果某个矩形区域在所有弱分类器中都被归结为正类，那么可以认为该区域是存在人脸的。</li>
</ol>
<p>其中，弱分类器训练的具体步骤如下：</p>
<ol>
<li>对于每个特征$f$，计算所有训练样本的特征值，并将其排序：</li>
<li>扫描一遍排好序的特征值，对排好序的表中的每个元素，计算下面四个值：<ul>
<li>计算全部正例的权重和$T^+$；</li>
<li>计算全部负例的权重和$T^-$；</li>
<li>计算该元素前之前的正例的权重和$S^+$；</li>
<li>计算该元素前之前的负例的权重和$S^-$</li>
</ul>
</li>
<li>选取当前元素的特征值$F_{k,j}$和它前面的一个特征值$F_{k,j−1}$之间的数作为阈值，所得到的弱分类器就在当前元素处把样本分开 —— 也就是说这个阈值对应的弱分类器将当前元素前的所有元素分为人脸（或非人脸），而把当前元素后（含）的所有元素分为非人脸（或人脸）。该阈值的分类误差为：</li>
</ol>
<script type="math/tex; mode=display">e=min(S^++(T^−−S^−),S^−+(T^+−S^+))</script><p>于是，通过把这个排序表从头到尾扫描一遍就可以为弱分类器选择使分类误差最小的阈值（最优阈值），也就是选取了一个最佳弱分类器。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><h3 id="训练步骤"><a href="#训练步骤" class="headerlink" title="训练步骤"></a>训练步骤</h3><p>从上面所述内容我们可以总结Haar分类器训练的五大步骤：</p>
<ol>
<li>准备人脸、非人脸样本集；</li>
<li>使用Haar特征做检测；</li>
<li>使用积分图（Integral Image）对Haar特征求值进行加速；</li>
<li>使用AdaBoost算法训练区分人脸和非人脸的强分类器；</li>
<li>使用筛选式级联把强分类器级联到一起，提高准确率</li>
</ol>
<h3 id="Haar的局限性"><a href="#Haar的局限性" class="headerlink" title="Haar的局限性"></a>Haar的局限性</h3><ul>
<li>仅为人脸检测，非人脸“辩识”，即只能框出人脸的位置，看不出人脸是谁。</li>
<li>仅能标出静态图片和视频帧上的人脸、人眼和微笑，不能进行“活体识别”，即不能看出这张脸是真人还是手机上的照片，如果用于人脸打卡签到、人脸支付的话会带来潜在的安全风险。</li>
<li>仅为普通的机器学习方法，没有用到深度学习和深层神经网络。</li>
</ul>
<blockquote>
<p>参考链接：</p>
</blockquote>
<ul>
<li><a href="https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_objdetect/py_face_detection/py_face_detection.html#face-detection" target="_blank" rel="noopener">https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_objdetect/py_face_detection/py_face_detection.html#face-detection</a></li>
<li><a href="https://github.com/TommyZihao/zihaoopencv/blob/master/%E7%AC%AC%E5%8D%81%E7%AB%A0%EF%BC%9A%E7%89%A9%E4%BD%93%E6%A3%80%E6%B5%8B%E4%B8%8E%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E3%80%90%E5%AD%90%E8%B1%AA%E5%85%84opencv-python%E6%95%99%E7%A8%8B%E3%80%91.md" target="_blank" rel="noopener">https://github.com/TommyZihao/zihaoopencv/blob/master/%E7%AC%AC%E5%8D%81%E7%AB%A0%EF%BC%9A%E7%89%A9%E4%BD%93%E6%A3%80%E6%B5%8B%E4%B8%8E%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E3%80%90%E5%AD%90%E8%B1%AA%E5%85%84opencv-python%E6%95%99%E7%A8%8B%E3%80%91.md</a></li>
<li><a href="https://github.com/datawhalechina/team-learning/blob/master/03%20%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E5%9F%BA%E7%A1%80%EF%BC%9A%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%EF%BC%88%E4%B8%8B%EF%BC%89/Task03%20Haar%E7%89%B9%E5%BE%81%E6%8F%8F%E8%BF%B0%E7%AE%97%E5%AD%90.md" target="_blank" rel="noopener">https://github.com/datawhalechina/team-learning/blob/master/03%20%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E5%9F%BA%E7%A1%80%EF%BC%9A%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%EF%BC%88%E4%B8%8B%EF%BC%89/Task03%20Haar%E7%89%B9%E5%BE%81%E6%8F%8F%E8%BF%B0%E7%AE%97%E5%AD%90.md</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/100217697" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/100217697</a></li>
<li><a href="https://blog.csdn.net/chutu2018/article/details/106983147/" target="_blank" rel="noopener">https://blog.csdn.net/chutu2018/article/details/106983147/</a></li>
<li><a href="https://blog.csdn.net/playezio/article/details/80471000" target="_blank" rel="noopener">https://blog.csdn.net/playezio/article/details/80471000</a></li>
<li><a href="https://www.cnblogs.com/recoverableTi/p/13214405.html" target="_blank" rel="noopener">https://www.cnblogs.com/recoverableTi/p/13214405.html</a></li>
</ul>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <div class="declare">
      <ul class="post-copyright">
        <li>
          <i class="ri-copyright-line"></i>
          <strong>版权声明： </strong>
          本博客所有文章除特别声明外，著作权归作者所有。转载请注明出处！
        </li>
      </ul>
    </div>
    
    <footer class="article-footer">
       
<div class="share-btn">
      <span class="share-sns share-outer">
        <i class="ri-share-forward-line"></i>
        分享
      </span>
      <div class="share-wrap">
        <i class="arrow"></i>
        <div class="share-icons">
          
          <a class="weibo share-sns" href="javascript:;" data-type="weibo">
            <i class="ri-weibo-fill"></i>
          </a>
          <a class="weixin share-sns wxFab" href="javascript:;" data-type="weixin">
            <i class="ri-wechat-fill"></i>
          </a>
          <a class="qq share-sns" href="javascript:;" data-type="qq">
            <i class="ri-qq-fill"></i>
          </a>
          <a class="douban share-sns" href="javascript:;" data-type="douban">
            <i class="ri-douban-line"></i>
          </a>
          <!-- <a class="qzone share-sns" href="javascript:;" data-type="qzone">
            <i class="icon icon-qzone"></i>
          </a> -->
          
          <a class="facebook share-sns" href="javascript:;" data-type="facebook">
            <i class="ri-facebook-circle-fill"></i>
          </a>
          <a class="twitter share-sns" href="javascript:;" data-type="twitter">
            <i class="ri-twitter-fill"></i>
          </a>
          <a class="google share-sns" href="javascript:;" data-type="google">
            <i class="ri-google-fill"></i>
          </a>
        </div>
      </div>
</div>

<div class="wx-share-modal">
    <a class="modal-close" href="javascript:;"><i class="ri-close-circle-line"></i></a>
    <p>扫一扫，分享到微信</p>
    <div class="wx-qrcode">
      <img src="//api.qrserver.com/v1/create-qr-code/?size=150x150&data=https://chenkai66.github.io/posts/7e50584a.html" alt="微信分享二维码">
    </div>
</div>

<div id="share-mask"></div>  
    </footer>
  </div>

   
  <nav class="article-nav">
    
      <a href="/posts/5f014252.html" class="article-nav-link">
        <strong class="article-nav-caption">上一篇</strong>
        <div class="article-nav-title">
          
            Harris特征点检测器-兴趣点检测
          
        </div>
      </a>
    
    
      <a href="/posts/ba35fcf2.html" class="article-nav-link">
        <strong class="article-nav-caption">下一篇</strong>
        <div class="article-nav-title">GAN学习（一）</div>
      </a>
    
  </nav>

   
<!-- valine评论 -->
<div id="vcomments-box">
  <div id="vcomments"></div>
</div>
<script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/valine@1.4.14/dist/Valine.min.js"></script>
<script>
  new Valine({
    el: "#vcomments",
    app_id: "TQy5bHTePagP10u5BBsesx61-gzGzoHsz",
    app_key: "O6UyJYxBFgMKQMjktBh4KGad",
    path: window.location.pathname,
    avatar: "monsterid",
    placeholder: "给我的文章加点评论吧~",
    recordIP: true,
  });
  const infoEle = document.querySelector("#vcomments .info");
  if (infoEle && infoEle.childNodes && infoEle.childNodes.length > 0) {
    infoEle.childNodes.forEach(function (item) {
      item.parentNode.removeChild(item);
    });
  }
</script>
<style>
  #vcomments-box {
    padding: 5px 30px;
  }

  @media screen and (max-width: 800px) {
    #vcomments-box {
      padding: 5px 0px;
    }
  }

  #vcomments-box #vcomments {
    background-color: #fff;
  }

  .v .vlist .vcard .vh {
    padding-right: 20px;
  }

  .v .vlist .vcard {
    padding-left: 10px;
  }
</style>

 
     
</article>

</section>
      <footer class="footer">
  <div class="outer">
    <ul>
      <li>
        Copyrights &copy;
        2020
        <i class="ri-heart-fill heart_icon"></i> chenk
      </li>
    </ul>
    <ul>
      <li>
        
        
        
        由 帅气的CK本尊 强力驱动
        
        
      </li>
    </ul>
    <ul>
      <li>
        
        
        <span>
  <span><i class="ri-user-3-fill"></i>访问人数:<span id="busuanzi_value_site_uv"></span></s>
  <span class="division">|</span>
  <span><i class="ri-eye-fill"></i>浏览次数:<span id="busuanzi_value_page_pv"></span></span>
</span>
        
      </li>
    </ul>
    <ul>
      
    </ul>
    <ul>
      <li>
        <!-- cnzz统计 -->
        
      </li>
    </ul>
  </div>
</footer>
      <div class="float_btns">
        <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>

<div class="todark" id="todark">
  <i class="ri-moon-line"></i>
</div>

      </div>
    </main>
    <aside class="sidebar on">
      <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/"><img src="/images/ayer-side.svg" alt="言念君子"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">主页</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/archives">归档</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories">分类</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags">标签</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="搜索">
        <i class="ri-search-line"></i>
      </a>
      
      
      <a class="nav-item-link" target="_blank" href="/atom.xml" title="RSS Feed">
        <i class="ri-rss-line"></i>
      </a>
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
    </aside>
    <script>
      if (window.matchMedia("(max-width: 768px)").matches) {
        document.querySelector('.content').classList.remove('on');
        document.querySelector('.sidebar').classList.remove('on');
      }
    </script>
    <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i>请我喝杯咖啡吧~</p>
  <div class="reward-box">
    
    <div class="reward-item">
      <img class="reward-img" src="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/img/alipay.jpg">
      <span class="reward-type">支付宝</span>
    </div>
    
    
    <div class="reward-item">
      <img class="reward-img" src="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/img/wechat.jpg">
      <span class="reward-type">微信</span>
    </div>
    
  </div>
</div>
    
<script src="/js/jquery-2.0.3.min.js"></script>


<script src="/js/lazyload.min.js"></script>

<!-- Tocbot -->


<script src="/js/tocbot.min.js"></script>

<script>
  tocbot.init({
    tocSelector: '.tocbot',
    contentSelector: '.article-entry',
    headingSelector: 'h1, h2, h3, h4, h5, h6',
    hasInnerContainers: true,
    scrollSmooth: true,
    scrollContainer: 'main',
    positionFixedSelector: '.tocbot',
    positionFixedClass: 'is-position-fixed',
    fixedSidebarOffset: 'auto'
  });
</script>

<script src="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.js"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.css">
<script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js"></script>

<script src="/dist/main.js"></script>

<!-- ImageViewer -->

<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css">
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"></script>

<script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // slider展开状态
                // todo: 这样不好，后面改成状态
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // 获得原图尺寸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script>

<!-- MathJax -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
      tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
  });

  MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for(i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
      }
  });
</script>

<script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.6/unpacked/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
  var ayerConfig = {
    mathjax: true
  }
</script>

<!-- Katex -->

<!-- busuanzi  -->


<script src="/js/busuanzi-2.3.pure.min.js"></script>


<!-- ClickLove -->

<!-- ClickBoom1 -->

<!-- ClickBoom2 -->


<script src="/js/clickBoom2.js"></script>


<!-- CodeCopy -->


<link rel="stylesheet" href="/css/clipboard.css">

<script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>
<script>
  function wait(callback, seconds) {
    var timelag = null;
    timelag = window.setTimeout(callback, seconds);
  }
  !function (e, t, a) {
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '<i class="ri-file-copy-2-line"></i><span>COPY</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      $(".article pre code").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        let $btn = $(e.trigger);
        $btn.addClass('copied');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-checkbox-circle-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPIED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-checkbox-circle-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
      clipboard.on('error', function(e) {
        e.clearSelection();
        let $btn = $(e.trigger);
        $btn.addClass('copy-failed');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-time-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPY FAILED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-time-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
    }
    initCopyCode();
  }(window, document);
</script>


<!-- CanvasBackground -->


<script src="/js/dz.js"></script>



    
  </div>
<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"model":{"jsonPath":"live2d-widget-model-haruto"},"display":{"position":"left","width":150,"height":300},"mobile":{"show":false},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>