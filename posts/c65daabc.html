<!DOCTYPE html>


<html lang="zh-CN">


<head>
  <meta charset="utf-8" />
    
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
  <title>
    泰坦尼克号生存率预测 |  言念君子
  </title>
  <meta name="generator" content="hexo-theme-ayer">
  
  <link rel="shortcut icon" href="/favicon.ico" />
  
  
<link rel="stylesheet" href="/dist/main.css">

  
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/css/remixicon.min.css">

  
<link rel="stylesheet" href="/css/custom.css">

  
  
<script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script>

  
  

  

</head>

</html>

<body>
  <div id="app">
    
      
      <canvas width="1777" height="841"
        style="position: fixed; left: 0px; top: 0px; z-index: 99999; pointer-events: none;"></canvas>
      
    <main class="content on">
      <section class="outer">
  <article
  id="post-泰坦尼克号生存率预测"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h1 class="article-title sea-center" style="border-left:0" itemprop="name">
  泰坦尼克号生存率预测
</h1>
 

    </header>
     
    <div class="article-meta">
      <a href="/posts/c65daabc.html" class="article-date">
  <time datetime="2020-08-17T02:00:32.799Z" itemprop="datePublished">2020-08-17</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/Match/">Match</a>
  </div>
  
<div class="word_count">
    <span class="post-time">
        <span class="post-meta-item-icon">
            <i class="ri-quill-pen-line"></i>
            <span class="post-meta-item-text"> 字数统计:</span>
            <span class="post-count">3.6k</span>
        </span>
    </span>

    <span class="post-time">
        &nbsp; | &nbsp;
        <span class="post-meta-item-icon">
            <i class="ri-book-open-line"></i>
            <span class="post-meta-item-text"> 阅读时长≈</span>
            <span class="post-count">16 分钟</span>
        </span>
    </span>
</div>
 
    </div>
      
    <div class="tocbot"></div>




  
    <div class="article-entry" itemprop="articleBody">
       
  <p>我们首先在Kaggle上找到对应的竞赛页面，报名参赛下载数据，于是我们得到了一个train.csv和test.csv文件，由于这个比赛比较简单，我们也简简单单地先按照套路完成数据探索（数据可视化）、数据预处理、模型搭建以及跑测试结果这几个步骤。现在我们开动吧~</p>
<h1 id="数据概述与可视化"><a href="#数据概述与可视化" class="headerlink" title="数据概述与可视化"></a>数据概述与可视化</h1><h2 id="数据概述"><a href="#数据概述" class="headerlink" title="数据概述"></a>数据概述</h2><p>首先我们导入我们的训练数据和测试数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">train_data = pd.read_csv(<span class="string">"input/train.csv"</span>, index_col=<span class="number">0</span>)</span><br><span class="line">test_data = pd.read_csv(<span class="string">"input/test.csv"</span>, index_col=<span class="number">0</span>)</span><br><span class="line">train_data.head()</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E5%8F%B7%E7%94%9F%E5%AD%98%E7%8E%87%E9%A2%84%E6%B5%8B/1.png" alt></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_data.describe()</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E5%8F%B7%E7%94%9F%E5%AD%98%E7%8E%87%E9%A2%84%E6%B5%8B/2.png" alt></p>
<p>通过describe()函数我们可以简单地看出哪些是数值型数据哪些是字符型数据，对于字符型数据我们当然要转换成数值型数据来处理，比如可以转换成0-1编码的数值型，但需要注意的是，对于一些数值型数据却未必就不需要进一步的处理了，比如Pclass特征，从名字我们就可以看出这是标识仓位等级的特征，取值范围为[1, 2, 3]，这个特征我们不应该简单地当作一个数值型数据放进分类模型中直接跑，应该把它转变为one-hot编码，标识乘客不同的仓位，这一步我们将在数据预处理步骤完成。</p>
<p>我们再看看数据中值为null的数据，这是我们后面需要进一步处理的：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_data.isnull().sum().sort_values(ascending=<span class="literal">False</span>).head(<span class="number">4</span>)</span><br></pre></td></tr></table></figure>
<p>显示结果为：</p>
<blockquote>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Cabin       687</span><br><span class="line">Age         177</span><br><span class="line">Embarked      2</span><br><span class="line">Fare          0</span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure>
</blockquote>
<h2 id="数据可视化"><a href="#数据可视化" class="headerlink" title="数据可视化"></a>数据可视化</h2><p>为了这篇文章看起来内容多一点（误），我们可以画多点图来展示数据信息，想直接进行数据预处理的读者可以跳过这部分，这部分内容大多来自<a href="https://www.kaggle.com/nadintamer/titanic-survival-predictions-beginner" target="_blank" rel="noopener">Kaggle官网的一篇notebook</a>。</p>
<h3 id="性别与生存率"><a href="#性别与生存率" class="headerlink" title="性别与生存率"></a>性别与生存率</h3><p>首先我们应该还记得电影里感人的“女士优先”策略：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.barplot(x=<span class="string">"Sex"</span>, y=<span class="string">"Survived"</span>, data=train_data)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E5%8F%B7%E7%94%9F%E5%AD%98%E7%8E%87%E9%A2%84%E6%B5%8B/sex.png" alt></p>
<p>这里我们可以看出女性的生存率远大于男性，这也很符合电影的情节。</p>
<h3 id="仓位等级（社会等级）与生存率"><a href="#仓位等级（社会等级）与生存率" class="headerlink" title="仓位等级（社会等级）与生存率"></a>仓位等级（社会等级）与生存率</h3><p>我们还可以猜测不同仓位的乘客应有不同的获救率：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#draw a bar plot of survival by Pclass</span></span><br><span class="line">sns.barplot(x=<span class="string">"Pclass"</span>, y=<span class="string">"Survived"</span>, data=train)</span><br><span class="line"></span><br><span class="line"><span class="comment">#print percentage of people by Pclass that survived</span></span><br><span class="line">print(<span class="string">"Percentage of Pclass = 1 who survived:"</span>, train[<span class="string">"Survived"</span>][train[<span class="string">"Pclass"</span>] == <span class="number">1</span>].value_counts(normalize = <span class="literal">True</span>)[<span class="number">1</span>]*<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"Percentage of Pclass = 2 who survived:"</span>, train[<span class="string">"Survived"</span>][train[<span class="string">"Pclass"</span>] == <span class="number">2</span>].value_counts(normalize = <span class="literal">True</span>)[<span class="number">1</span>]*<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"Percentage of Pclass = 3 who survived:"</span>, train[<span class="string">"Survived"</span>][train[<span class="string">"Pclass"</span>] == <span class="number">3</span>].value_counts(normalize = <span class="literal">True</span>)[<span class="number">1</span>]*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E5%8F%B7%E7%94%9F%E5%AD%98%E7%8E%87%E9%A2%84%E6%B5%8B/pclass.png" alt></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Percentage of Pclass &#x3D; 1 who survived: 62.96296296296296</span><br><span class="line">Percentage of Pclass &#x3D; 2 who survived: 47.28260869565217</span><br><span class="line">Percentage of Pclass &#x3D; 3 who survived: 24.236252545824847</span><br></pre></td></tr></table></figure>
<p>数据结果还是很现实的，贵的仓位自然有更高的生存率 ，不然我花这冤枉钱干嘛，生死面前不是人人平等。</p>
<blockquote>
<p>As predicted, people with higher socioeconomic class had a higher rate of survival. (62.9% vs. 47.3% vs. 24.2%)</p>
</blockquote>
<h3 id="家属数与生存率"><a href="#家属数与生存率" class="headerlink" title="家属数与生存率"></a>家属数与生存率</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#draw a bar plot for SibSp vs. survival</span></span><br><span class="line">sns.barplot(x=<span class="string">"SibSp"</span>, y=<span class="string">"Survived"</span>, data=train)</span><br><span class="line"></span><br><span class="line"><span class="comment">#I won't be printing individual percent values for all of these.</span></span><br><span class="line">print(<span class="string">"Percentage of SibSp = 0 who survived:"</span>, train[<span class="string">"Survived"</span>][train[<span class="string">"SibSp"</span>] == <span class="number">0</span>].value_counts(normalize = <span class="literal">True</span>)[<span class="number">1</span>]*<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"Percentage of SibSp = 1 who survived:"</span>, train[<span class="string">"Survived"</span>][train[<span class="string">"SibSp"</span>] == <span class="number">1</span>].value_counts(normalize = <span class="literal">True</span>)[<span class="number">1</span>]*<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"Percentage of SibSp = 2 who survived:"</span>, train[<span class="string">"Survived"</span>][train[<span class="string">"SibSp"</span>] == <span class="number">2</span>].value_counts(normalize = <span class="literal">True</span>)[<span class="number">1</span>]*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Percentage of SibSp &#x3D; 0 who survived: 34.53947368421053</span><br><span class="line">Percentage of SibSp &#x3D; 1 who survived: 53.588516746411486</span><br><span class="line">Percentage of SibSp &#x3D; 2 who survived: 46.42857142857143</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E5%8F%B7%E7%94%9F%E5%AD%98%E7%8E%87%E9%A2%84%E6%B5%8B/sibsp.png" alt></p>
<p>这里可以看出，有一个兄弟姐妹的一般有更高的生存率，所以快去鼓励爸爸妈妈生个弟弟妹妹吧~</p>
<blockquote>
<p>In general, it’s clear that people with more siblings or spouses aboard were less likely to survive. However, contrary to expectations, people with no siblings or spouses were less to likely to survive than those with one or two. (34.5% vs 53.4% vs. 46.4%)</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#draw a bar plot for Parch vs. survival</span></span><br><span class="line">sns.barplot(x=<span class="string">"Parch"</span>, y=<span class="string">"Survived"</span>, data=train)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E5%8F%B7%E7%94%9F%E5%AD%98%E7%8E%87%E9%A2%84%E6%B5%8B/patch.png" alt></p>
<p>看起来独自旅游的人们生存率更低，想想眼眶竟湿润了</p>
<blockquote>
<p>People with less than four parents or children aboard are more likely to survive than those with four or more. Again, people traveling alone are less likely to survive than those with 1-3 parents or children.</p>
</blockquote>
<h3 id="年龄与生存率"><a href="#年龄与生存率" class="headerlink" title="年龄与生存率"></a>年龄与生存率</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#sort the ages into logical categories</span></span><br><span class="line">train[<span class="string">"Age"</span>] = train[<span class="string">"Age"</span>].fillna(<span class="number">-0.5</span>)</span><br><span class="line">test[<span class="string">"Age"</span>] = test[<span class="string">"Age"</span>].fillna(<span class="number">-0.5</span>)</span><br><span class="line">bins = [<span class="number">-1</span>, <span class="number">0</span>, <span class="number">5</span>, <span class="number">12</span>, <span class="number">18</span>, <span class="number">24</span>, <span class="number">35</span>, <span class="number">60</span>, np.inf]</span><br><span class="line">labels = [<span class="string">'Unknown'</span>, <span class="string">'Baby'</span>, <span class="string">'Child'</span>, <span class="string">'Teenager'</span>, <span class="string">'Student'</span>, <span class="string">'Young Adult'</span>, <span class="string">'Adult'</span>, <span class="string">'Senior'</span>]</span><br><span class="line">train[<span class="string">'AgeGroup'</span>] = pd.cut(train[<span class="string">"Age"</span>], bins, labels = labels)</span><br><span class="line">test[<span class="string">'AgeGroup'</span>] = pd.cut(test[<span class="string">"Age"</span>], bins, labels = labels)</span><br><span class="line"></span><br><span class="line"><span class="comment">#draw a bar plot of Age vs. survival</span></span><br><span class="line">sns.barplot(x=<span class="string">"AgeGroup"</span>, y=<span class="string">"Survived"</span>, data=train)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E5%8F%B7%E7%94%9F%E5%AD%98%E7%8E%87%E9%A2%84%E6%B5%8B/age.png" alt></p>
<p>这张图表绘制用到了pandas的一个方法：cut（），可以用这个方法对数据进行切分，我们得到很显然的一个结论，婴儿的生存率神他妈高（我觉得很大一部分原因是不占空间）</p>
<h3 id="仓位特征是否存在与生存率"><a href="#仓位特征是否存在与生存率" class="headerlink" title="仓位特征是否存在与生存率"></a>仓位特征是否存在与生存率</h3><p>这是个奇怪的指标，据作者描述：</p>
<blockquote>
<p>I think the idea here is that people with recorded cabin numbers are of higher socioeconomic class, and thus more likely to survive. </p>
</blockquote>
<p>好吧我们看看：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">test[<span class="string">"CabinBool"</span>] = (test[<span class="string">"Cabin"</span>].notnull().astype(<span class="string">'int'</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">#calculate percentages of CabinBool vs. survived</span></span><br><span class="line">print(<span class="string">"Percentage of CabinBool = 1 who survived:"</span>, train[<span class="string">"Survived"</span>][train[<span class="string">"CabinBool"</span>] == <span class="number">1</span>].value_counts(normalize = <span class="literal">True</span>)[<span class="number">1</span>]*<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"Percentage of CabinBool = 0 who survived:"</span>, train[<span class="string">"Survived"</span>][train[<span class="string">"CabinBool"</span>] == <span class="number">0</span>].value_counts(normalize = <span class="literal">True</span>)[<span class="number">1</span>]*<span class="number">100</span>)</span><br><span class="line"><span class="comment">#draw a bar plot of CabinBool vs. survival</span></span><br><span class="line">sns.barplot(x=<span class="string">"CabinBool"</span>, y=<span class="string">"Survived"</span>, data=train)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Percentage of CabinBool &#x3D; 1 who survived: 66.66666666666666</span><br><span class="line">Percentage of CabinBool &#x3D; 0 who survived: 29.985443959243085</span><br></pre></td></tr></table></figure>
</blockquote>
<p><img src="/Pic/%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E5%8F%B7%E7%94%9F%E5%AD%98%E7%8E%87%E9%A2%84%E6%B5%8B/cabin_.png" alt></p>
<p>脑洞确实大，结果确实不赖~</p>
<h3 id="热力图"><a href="#热力图" class="headerlink" title="热力图"></a>热力图</h3><p>我们还可以给数据画上美丽的热力图，虽然没什么卵用：</p>
<p><img src="/Pic/%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E5%8F%B7%E7%94%9F%E5%AD%98%E7%8E%87%E9%A2%84%E6%B5%8B/sns.png" alt></p>
<h1 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h1><h2 id="拼接数据集"><a href="#拼接数据集" class="headerlink" title="拼接数据集"></a>拼接数据集</h2><p>首先我们讲训练集中的Survived特征提取出来，这是我们需要预测的目标函数，这部分也是train_data和test_data的不同点，接着我们可以讲训练集和测试集的数据拼接起来一起进行数据预处理，当然在实际中我们是无从得知测试数据的，但在比赛中为了方便我们可以统一进行处理：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y_train = train_data.pop(<span class="string">"Survived"</span>)</span><br><span class="line">data_all = pd.concat((train_data, test_data), axis=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<h2 id="处理Name特征，提取出Title"><a href="#处理Name特征，提取出Title" class="headerlink" title="处理Name特征，提取出Title"></a>处理Name特征，提取出Title</h2><p>从左往右看我们首先可以看到Name这个特征是比较碍眼的，很多人可能直接把它去掉了，但仔细观察我们可以发现这一列特征里都含有名字的前缀，比如”Mr.”，”Mrs.“，”Miss”等，只要学过小学一年级英语的都知道这个特征在一定程度上会代表阶级地位，婚配情况等，我们可以将这个特征做一个映射，实现方式如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">title = pd.DataFrame()</span><br><span class="line">title[<span class="string">"Title"</span>] = data_all[<span class="string">"Name"</span>].map(<span class="keyword">lambda</span> name:name.split(<span class="string">","</span>)[<span class="number">1</span>].split(<span class="string">"."</span>)[<span class="number">0</span>].strip())</span><br><span class="line"><span class="comment"># title.head()</span></span><br><span class="line">Title_Dictionary = &#123;</span><br><span class="line">    <span class="string">"Capt"</span>:       <span class="string">"Officer"</span>,</span><br><span class="line">    <span class="string">"Col"</span>:        <span class="string">"Officer"</span>,</span><br><span class="line">    <span class="string">"Major"</span>:      <span class="string">"Officer"</span>,</span><br><span class="line">    <span class="string">"Jonkheer"</span>:   <span class="string">"Royalty"</span>,</span><br><span class="line">    <span class="string">"Don"</span>:        <span class="string">"Royalty"</span>,</span><br><span class="line">    <span class="string">"Sir"</span> :       <span class="string">"Royalty"</span>,</span><br><span class="line">    <span class="string">"Dr"</span>:         <span class="string">"Officer"</span>,</span><br><span class="line">    <span class="string">"Rev"</span>:        <span class="string">"Officer"</span>,</span><br><span class="line">    <span class="string">"the Countess"</span>:<span class="string">"Royalty"</span>,</span><br><span class="line">    <span class="string">"Dona"</span>:       <span class="string">"Royalty"</span>,</span><br><span class="line">    <span class="string">"Mme"</span>:        <span class="string">"Mrs"</span>,</span><br><span class="line">    <span class="string">"Mlle"</span>:       <span class="string">"Miss"</span>,</span><br><span class="line">    <span class="string">"Ms"</span>:         <span class="string">"Mrs"</span>,</span><br><span class="line">    <span class="string">"Mr"</span> :        <span class="string">"Mr"</span>,</span><br><span class="line">    <span class="string">"Mrs"</span> :       <span class="string">"Mrs"</span>,</span><br><span class="line">    <span class="string">"Miss"</span> :      <span class="string">"Miss"</span>,</span><br><span class="line">    <span class="string">"Master"</span> :    <span class="string">"Master"</span>,</span><br><span class="line">    <span class="string">"Lady"</span> :      <span class="string">"Royalty"</span></span><br><span class="line">&#125;</span><br><span class="line">title[ <span class="string">'Title'</span> ] = title.Title.map(Title_Dictionary)</span><br><span class="line">title = pd.get_dummies(title.Title)</span><br><span class="line"><span class="comment"># title.head()</span></span><br><span class="line">data_all = pd.concat((data_all, title), axis=<span class="number">1</span>)</span><br><span class="line">data_all.pop(<span class="string">"Name"</span>)</span><br><span class="line">data_all.head()</span><br></pre></td></tr></table></figure>
<p>上面这段是什么意思呢？我们可以将种类众多的头衔特征先进行归类，比如”Don”，”Sir”，”Jonkheer”这几个头衔出现的次数极低，大约每个出现次数只有不到十个，因此我们可以将意思相近的归为一类便于模型运行。然后我们用get_dummies将这些特征转为one-hot向量，得到的结果如下：</p>
<p><img src="/Pic/%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E5%8F%B7%E7%94%9F%E5%AD%98%E7%8E%87%E9%A2%84%E6%B5%8B/3.png" alt></p>
<h2 id="提取其他特征"><a href="#提取其他特征" class="headerlink" title="提取其他特征"></a>提取其他特征</h2><p>这个 Ticket特征比较麻烦懒得搞了，先把它删掉吧，然后Cabin特征应该是很有用的，你想想嘛我们在船的不同位置到安全通道的距离当然是会随着Cabin位置的不同而不同的，我们简单提取A、B、C、D这几个仓位来作为特征，而不考虑C85、C123中的数字（表示某个仓中的位置），当然由于有些船在A、B、C、D等仓位可能都有安全通道，我们可能提取后面的数字会更适合，为了方便我们先不做此讨论：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">data_all[<span class="string">"Cabin"</span>].fillna(<span class="string">"NA"</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">data_all[<span class="string">"Cabin"</span>] = data_all[<span class="string">"Cabin"</span>].map(<span class="keyword">lambda</span> s:s[<span class="number">0</span>])</span><br><span class="line">data_all.pop(<span class="string">"Ticket"</span>)</span><br></pre></td></tr></table></figure>
<p>前面也说了Pclass更适合作为One-hot型特征出现，我们先将之转换为字符型特征再进行归类，这里我们顺手把几个靠谱的类别标签做One-hot特征：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">data_all[<span class="string">"Pclass"</span>] = data_all[<span class="string">"Pclass"</span>].astype(str)</span><br><span class="line">feature_dummies = pd.get_dummies(data_all[[<span class="string">"Pclass"</span>, <span class="string">"Sex"</span>, <span class="string">"Embarked"</span>, <span class="string">"Cabin"</span>]])</span><br><span class="line"><span class="comment"># feature_dummies.head()</span></span><br><span class="line">data_all.drop([<span class="string">"Pclass"</span>, <span class="string">"Sex"</span>, <span class="string">"Embarked"</span>, <span class="string">"Cabin"</span>], inplace=<span class="literal">True</span>, axis=<span class="number">1</span>)</span><br><span class="line">data_all = pd.concat((data_all, feature_dummies), axis=<span class="number">1</span>)</span><br><span class="line">data_all.head()</span><br></pre></td></tr></table></figure>
<p>于是我们将特征集合由原来的11列扩充到了27列，噢糟糕我们前面忘了做缺失值填充，不要紧我们现在做也不晚：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mean_cols = data_all.mean()</span><br><span class="line">data_all = data_all.fillna(mean_cols)</span><br></pre></td></tr></table></figure>
<p>这里是使用了平均值对Age和Embarked两个特征进行填充，由于Age刚好是数值型特征，这种填充方式是合理的，且Embarked只有两个缺失值，因此随便填充啦~不碍事的。</p>
<h2 id="将训练集测试集重新分开"><a href="#将训练集测试集重新分开" class="headerlink" title="将训练集测试集重新分开"></a>将训练集测试集重新分开</h2><p>在模型搭建之前不要忘了之前我们拼在一起的训练集和测试集噢，还记得最开始读取数据的时候加入的index_col嘛，这里刚好派上用场啦：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">train_df = data_all.loc[train_data.index]</span><br><span class="line">test_df = data_all.loc[test_data.index]</span><br><span class="line">print(train_df.shape, test_df.shape)</span><br></pre></td></tr></table></figure>
<p>打印结果是(891, 27) (418, 27)，符合原训练集测试集的大小，我们的粗略数据预处理就到此为止了，下面进行模型搭建~</p>
<h1 id="模型搭建"><a href="#模型搭建" class="headerlink" title="模型搭建"></a>模型搭建</h1><h2 id="Random-Forest"><a href="#Random-Forest" class="headerlink" title="Random Forest"></a>Random Forest</h2><p>首先导入sklearn的包</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line"><span class="keyword">import</span> sklearn</span><br></pre></td></tr></table></figure>
<p>然后设置不同的树最大深度进行参数调优：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line">depth_ = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>]</span><br><span class="line">scores = []</span><br><span class="line"><span class="keyword">for</span> depth <span class="keyword">in</span> depth_:</span><br><span class="line">    clf = RandomForestClassifier(n_estimators=<span class="number">100</span>, max_depth=depth, random_state=<span class="number">0</span>)</span><br><span class="line">    test_score = cross_val_score(clf, train_df, y_train, cv=<span class="number">10</span>, scoring=<span class="string">"precision"</span>)</span><br><span class="line">    scores.append(np.mean(test_score))</span><br><span class="line">plt.plot(depth_, scores)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E5%8F%B7%E7%94%9F%E5%AD%98%E7%8E%87%E9%A2%84%E6%B5%8B/4.png" alt></p>
<p>得到了这样一张图，这张图大致反映了模型中树的最大深度以6为最佳，此时可以达到0.84左右的验证准确率，我们当然可以继续调整其他参数获得更优的结果，但接下来我们先继续讨论其他模型。</p>
<h2 id="Gradient-Boosting-Classifier"><a href="#Gradient-Boosting-Classifier" class="headerlink" title="Gradient Boosting Classifier"></a>Gradient Boosting Classifier</h2><p>代码和上面差不多：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> GradientBoostingClassifier</span><br><span class="line">depth_ = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>]</span><br><span class="line">scores = []</span><br><span class="line"><span class="keyword">for</span> depth <span class="keyword">in</span> depth_:</span><br><span class="line">    clf = GradientBoostingClassifier(n_estimators=<span class="number">100</span>, max_depth=depth, random_state=<span class="number">0</span>)</span><br><span class="line">    test_score = cross_val_score(clf, train_df, y_train, cv=<span class="number">10</span>, scoring=<span class="string">"precision"</span>)</span><br><span class="line">    scores.append(np.mean(test_score))</span><br><span class="line">plt.plot(depth_, scores)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E5%8F%B7%E7%94%9F%E5%AD%98%E7%8E%87%E9%A2%84%E6%B5%8B/gb.png" alt></p>
<p>成功率最高似乎接近0.82</p>
<h2 id="Bagging"><a href="#Bagging" class="headerlink" title="Bagging"></a>Bagging</h2><p>Bagging把很多小分类器放在一起，每个train随机的一部分数据，然后把它们的最终结果综合起来（多数投票制）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> BaggingClassifier</span><br><span class="line">params = [<span class="number">1</span>, <span class="number">10</span>, <span class="number">15</span>, <span class="number">20</span>, <span class="number">25</span>, <span class="number">30</span>, <span class="number">40</span>]</span><br><span class="line">test_scores = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> param <span class="keyword">in</span> params:</span><br><span class="line">    clf = BaggingClassifier(n_estimators=param)</span><br><span class="line">    test_score = cross_val_score(clf, train_df, y_train, cv=<span class="number">10</span>, scoring=<span class="string">"precision"</span>)</span><br><span class="line">    test_scores.append(np.mean(test_score))</span><br><span class="line">plt.plot(params, test_scores)</span><br></pre></td></tr></table></figure>
<p>结果又不稳定又不好：</p>
<p><img src="/Pic/%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E5%8F%B7%E7%94%9F%E5%AD%98%E7%8E%87%E9%A2%84%E6%B5%8B/bagging.png" alt></p>
<h2 id="RidgeClassifier"><a href="#RidgeClassifier" class="headerlink" title="RidgeClassifier"></a>RidgeClassifier</h2><p>下面就不说废话了，一个个试就对了：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> RidgeClassifier</span><br><span class="line">alphas = np.logspace(<span class="number">-3</span>, <span class="number">2</span>, <span class="number">50</span>)</span><br><span class="line">test_scores = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> alpha <span class="keyword">in</span> alphas:</span><br><span class="line">    clf = RidgeClassifier(alpha)</span><br><span class="line">    test_score = cross_val_score(clf, train_df, y_train, cv=<span class="number">10</span>, scoring=<span class="string">"precision"</span>)</span><br><span class="line">    test_scores.append(np.mean(test_score))</span><br><span class="line">plt.plot(alphas, test_scores)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E5%8F%B7%E7%94%9F%E5%AD%98%E7%8E%87%E9%A2%84%E6%B5%8B/ridge.png" alt></p>
<h2 id="RidgeClassifier-Bagging"><a href="#RidgeClassifier-Bagging" class="headerlink" title="RidgeClassifier + Bagging"></a>RidgeClassifier + Bagging</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">ridge = RidgeClassifier(alpha=<span class="number">5</span>)</span><br><span class="line">params = [<span class="number">1</span>, <span class="number">10</span>, <span class="number">15</span>, <span class="number">20</span>, <span class="number">25</span>, <span class="number">30</span>, <span class="number">40</span>]</span><br><span class="line">test_scores = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> param <span class="keyword">in</span> params:</span><br><span class="line">    clf = BaggingClassifier(n_estimators=param, base_estimator=ridge)</span><br><span class="line">    test_score = cross_val_score(clf, train_df, y_train, cv=<span class="number">10</span>, scoring=<span class="string">"precision"</span>)</span><br><span class="line">    test_scores.append(np.mean(test_score))</span><br><span class="line">plt.plot(params, test_scores)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E5%8F%B7%E7%94%9F%E5%AD%98%E7%8E%87%E9%A2%84%E6%B5%8B/ridge+bagging.png" alt></p>
<p>结果比使用默认模型的Bagging策略稍好一些。</p>
<h2 id="XGBClassifier"><a href="#XGBClassifier" class="headerlink" title="XGBClassifier"></a>XGBClassifier</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBClassifier</span><br><span class="line">params = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]</span><br><span class="line">test_scores = []</span><br><span class="line"><span class="keyword">for</span> param <span class="keyword">in</span> params:</span><br><span class="line">    clf = XGBClassifier(max_depth=param)</span><br><span class="line">    test_score = cross_val_score(clf, train_df, y_train, cv=<span class="number">10</span>, scoring=<span class="string">"precision"</span>)</span><br><span class="line">    test_scores.append(np.mean(test_score))</span><br><span class="line">plt.plot(params, test_scores)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E5%8F%B7%E7%94%9F%E5%AD%98%E7%8E%87%E9%A2%84%E6%B5%8B/xgb.png" alt></p>
<h2 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h2><p>首先我们基于Keras搭建了一个简单的神经网络架构：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line">tf.keras.optimizers.Adam(</span><br><span class="line">    learning_rate=<span class="number">0.003</span>, beta_1=<span class="number">0.9</span>, beta_2=<span class="number">0.999</span>, epsilon=<span class="number">1e-07</span>, amsgrad=<span class="literal">False</span>,</span><br><span class="line">    name=<span class="string">'Adam'</span>, </span><br><span class="line">)</span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(Dense(<span class="number">32</span>, input_dim=train_df.shape[<span class="number">1</span>],kernel_initializer = <span class="string">'uniform'</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(Dense(<span class="number">32</span>, kernel_initializer = <span class="string">'uniform'</span>, activation = <span class="string">'relu'</span>))</span><br><span class="line">model.add(Dropout(<span class="number">0.4</span>))</span><br><span class="line">model.add(Dense(<span class="number">32</span>,kernel_initializer = <span class="string">'uniform'</span>, activation = <span class="string">'relu'</span>))</span><br><span class="line">model.add(Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>))</span><br><span class="line">    </span><br><span class="line">model.compile(loss=<span class="string">'binary_crossentropy'</span>, optimizer=<span class="string">'adam'</span>, metrics=[<span class="string">'accuracy'</span>])</span><br></pre></td></tr></table></figure>
<p>然后将模型放入train_df进行训练得到结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">history = model.fit(np.array(train_df), np.array(y_train), epochs=<span class="number">20</span>, batch_size=<span class="number">50</span>, validation_split = <span class="number">0.2</span>)</span><br></pre></td></tr></table></figure>
<p>最后一轮的结果为：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Epoch 20&#x2F;20</span><br><span class="line">712&#x2F;712 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 0s 43us&#x2F;step - loss: 0.4831 - accuracy: 0.7978 - val_loss: 0.3633 - val_accuracy: 0.8715</span><br></pre></td></tr></table></figure>
<p>可以看到实验结果还是不错的，我们看一看模型的架构：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.summary()</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">Model: &quot;sequential_1&quot;</span><br><span class="line">_________________________________________________________________</span><br><span class="line">Layer (type)                 Output Shape              Param #   </span><br><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line">dense_1 (Dense)              (None, 32)                896       </span><br><span class="line">_________________________________________________________________</span><br><span class="line">dense_2 (Dense)              (None, 32)                1056      </span><br><span class="line">_________________________________________________________________</span><br><span class="line">dropout_1 (Dropout)          (None, 32)                0         </span><br><span class="line">_________________________________________________________________</span><br><span class="line">dense_3 (Dense)              (None, 32)                1056      </span><br><span class="line">_________________________________________________________________</span><br><span class="line">dense_4 (Dense)              (None, 1)                 33        </span><br><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line">Total params: 3,041</span><br><span class="line">Trainable params: 3,041</span><br><span class="line">Non-trainable params: 0</span><br><span class="line">_________________________________________________________________</span><br></pre></td></tr></table></figure>
<p>测试模型：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scores = model.evaluate(train_df, y_train, batch_size=<span class="number">32</span>)</span><br><span class="line">print(scores)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">891&#x2F;891 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 0s 18us&#x2F;step</span><br><span class="line">[0.4208374666645872, 0.8316498398780823]</span><br></pre></td></tr></table></figure>
<p>可以看到效果和随机森林的最佳效果差不多。</p>
<h1 id="模型优化"><a href="#模型优化" class="headerlink" title="模型优化"></a>模型优化</h1><p>后续我们可以通过对这些表现比较好的模型再进行第二层的学习获得更好的分数。</p>
<p>首先我们将之前获得的几个比较好的结果一一定好参数放上来（这里只随便调了一个参数）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier, GradientBoostingClassifier, BaggingClassifier, AdaBoostClassifier</span><br><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> RidgeClassifier</span><br><span class="line"><span class="keyword">import</span> sklearn</span><br><span class="line"></span><br><span class="line">classifier_num = <span class="number">5</span></span><br><span class="line">clf = [<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> range(classifier_num)]</span><br><span class="line">clf[<span class="number">0</span>] = RandomForestClassifier(n_estimators=<span class="number">100</span>, max_depth=<span class="number">6</span>, random_state=<span class="number">0</span>)</span><br><span class="line">clf[<span class="number">1</span>] = GradientBoostingClassifier(n_estimators=<span class="number">100</span>, max_depth=<span class="number">4</span>, random_state=<span class="number">0</span>)</span><br><span class="line">clf[<span class="number">2</span>] = RidgeClassifier(<span class="number">5</span>)</span><br><span class="line">clf[<span class="number">3</span>] = BaggingClassifier(n_estimators=<span class="number">15</span>, base_estimator=clf[<span class="number">2</span>])</span><br><span class="line">clf[<span class="number">4</span>] = XGBClassifier(max_depth=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, Y_train, Y_test = train_test_split(train_df, y_train, random_state=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">predictFrame = pd.DataFrame()</span><br><span class="line"><span class="keyword">for</span> model <span class="keyword">in</span> clf:</span><br><span class="line">    model.fit(X_train, Y_train)</span><br><span class="line">    predictFrame[str(model)[:<span class="number">13</span>]] = model.predict(X_test)</span><br><span class="line">predictFrame.head()</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E5%8F%B7%E7%94%9F%E5%AD%98%E7%8E%87%E9%A2%84%E6%B5%8B/model_merge.png" alt></p>
<p>名字随意啦反正只要不重复就好了~然后将这个结果放入下一个分类器中学习，我没有试其他的就直接放进了随机森林分类器：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line">depth_ = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>]</span><br><span class="line">scores = []</span><br><span class="line"><span class="keyword">for</span> depth <span class="keyword">in</span> depth_:</span><br><span class="line">    clf_ = RandomForestClassifier(n_estimators=<span class="number">100</span>, max_depth=depth, random_state=<span class="number">0</span>)</span><br><span class="line">    test_score = cross_val_score(clf_, predictFrame, Y_test, cv=<span class="number">10</span>, scoring=<span class="string">"precision"</span>)</span><br><span class="line">    scores.append(np.mean(test_score))</span><br><span class="line">plt.plot(depth_, scores)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E5%8F%B7%E7%94%9F%E5%AD%98%E7%8E%87%E9%A2%84%E6%B5%8B/model_2.png" alt></p>
<p>好吧就定个参数为2，然后就将整体跑个结果试试：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">finalFrame = pd.DataFrame()</span><br><span class="line">XFrame = pd.DataFrame()</span><br><span class="line"><span class="keyword">for</span> model <span class="keyword">in</span> clf:</span><br><span class="line">    model.fit(train_df, y_train)</span><br><span class="line">    XFrame[str(model)[:<span class="number">13</span>]] = model.predict(train_df)</span><br><span class="line">    finalFrame[str(model)[:<span class="number">13</span>]] = model.predict(test_df)</span><br><span class="line">final_clf = RandomForestClassifier(n_estimators=<span class="number">100</span>, max_depth=<span class="number">2</span>, random_state=<span class="number">0</span>)</span><br><span class="line">final_clf.fit(XFrame, y_train)</span><br><span class="line">result = final_clf.predict(finalFrame)</span><br></pre></td></tr></table></figure>
<p>将result和passengerId一起拼接成一个Dataframe就直接输出看结果吧，比之前没有融合直接用随机森林结果稍好一些，但还是一样菜，毕竟只是用了几个简单的机器学习算法搞来搞去也没有认真调参，这个比赛就先这样收尾啦~</p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <div class="declare">
      <ul class="post-copyright">
        <li>
          <i class="ri-copyright-line"></i>
          <strong>版权声明： </strong>
          本博客所有文章除特别声明外，著作权归作者所有。转载请注明出处！
        </li>
      </ul>
    </div>
    
    <footer class="article-footer">
       
<div class="share-btn">
      <span class="share-sns share-outer">
        <i class="ri-share-forward-line"></i>
        分享
      </span>
      <div class="share-wrap">
        <i class="arrow"></i>
        <div class="share-icons">
          
          <a class="weibo share-sns" href="javascript:;" data-type="weibo">
            <i class="ri-weibo-fill"></i>
          </a>
          <a class="weixin share-sns wxFab" href="javascript:;" data-type="weixin">
            <i class="ri-wechat-fill"></i>
          </a>
          <a class="qq share-sns" href="javascript:;" data-type="qq">
            <i class="ri-qq-fill"></i>
          </a>
          <a class="douban share-sns" href="javascript:;" data-type="douban">
            <i class="ri-douban-line"></i>
          </a>
          <!-- <a class="qzone share-sns" href="javascript:;" data-type="qzone">
            <i class="icon icon-qzone"></i>
          </a> -->
          
          <a class="facebook share-sns" href="javascript:;" data-type="facebook">
            <i class="ri-facebook-circle-fill"></i>
          </a>
          <a class="twitter share-sns" href="javascript:;" data-type="twitter">
            <i class="ri-twitter-fill"></i>
          </a>
          <a class="google share-sns" href="javascript:;" data-type="google">
            <i class="ri-google-fill"></i>
          </a>
        </div>
      </div>
</div>

<div class="wx-share-modal">
    <a class="modal-close" href="javascript:;"><i class="ri-close-circle-line"></i></a>
    <p>扫一扫，分享到微信</p>
    <div class="wx-qrcode">
      <img src="//api.qrserver.com/v1/create-qr-code/?size=150x150&data=https://chenkai66.github.io/posts/c65daabc.html" alt="微信分享二维码">
    </div>
</div>

<div id="share-mask"></div>  
    </footer>
  </div>

   
  <nav class="article-nav">
    
      <a href="/posts/f41ee879.html" class="article-nav-link">
        <strong class="article-nav-caption">上一篇</strong>
        <div class="article-nav-title">
          
            金融量化分析基础（十一）—— 大小周期双频率策略
          
        </div>
      </a>
    
    
      <a href="/posts/5ad0b051.html" class="article-nav-link">
        <strong class="article-nav-caption">下一篇</strong>
        <div class="article-nav-title">R语言实战（二）</div>
      </a>
    
  </nav>

   
<!-- valine评论 -->
<div id="vcomments-box">
  <div id="vcomments"></div>
</div>
<script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/valine@1.4.14/dist/Valine.min.js"></script>
<script>
  new Valine({
    el: "#vcomments",
    app_id: "TQy5bHTePagP10u5BBsesx61-gzGzoHsz",
    app_key: "O6UyJYxBFgMKQMjktBh4KGad",
    path: window.location.pathname,
    avatar: "monsterid",
    placeholder: "给我的文章加点评论吧~",
    recordIP: true,
  });
  const infoEle = document.querySelector("#vcomments .info");
  if (infoEle && infoEle.childNodes && infoEle.childNodes.length > 0) {
    infoEle.childNodes.forEach(function (item) {
      item.parentNode.removeChild(item);
    });
  }
</script>
<style>
  #vcomments-box {
    padding: 5px 30px;
  }

  @media screen and (max-width: 800px) {
    #vcomments-box {
      padding: 5px 0px;
    }
  }

  #vcomments-box #vcomments {
    background-color: #fff;
  }

  .v .vlist .vcard .vh {
    padding-right: 20px;
  }

  .v .vlist .vcard {
    padding-left: 10px;
  }
</style>

 
     
</article>

</section>
      <footer class="footer">
  <div class="outer">
    <ul>
      <li>
        Copyrights &copy;
        2020
        <i class="ri-heart-fill heart_icon"></i> chenk
      </li>
    </ul>
    <ul>
      <li>
        
        
        
        由 Myself 强力驱动
        
        
      </li>
    </ul>
    <ul>
      <li>
        
        
        <span>
  <span><i class="ri-user-3-fill"></i>访问人数:<span id="busuanzi_value_site_uv"></span></s>
  <span class="division">|</span>
  <span><i class="ri-eye-fill"></i>浏览次数:<span id="busuanzi_value_page_pv"></span></span>
</span>
        
      </li>
    </ul>
    <ul>
      
    </ul>
    <ul>
      <li>
        <!-- cnzz统计 -->
        
      </li>
    </ul>
  </div>
</footer>
      <div class="float_btns">
        <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>

<div class="todark" id="todark">
  <i class="ri-moon-line"></i>
</div>

      </div>
    </main>
    <aside class="sidebar on">
      <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/"><img src="/images/ayer-side.svg" alt="言念君子"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">主页</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/archives">归档</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories">分类</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags">标签</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="搜索">
        <i class="ri-search-line"></i>
      </a>
      
      
      <a class="nav-item-link" target="_blank" href="/atom.xml" title="RSS Feed">
        <i class="ri-rss-line"></i>
      </a>
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
    </aside>
    <script>
      if (window.matchMedia("(max-width: 768px)").matches) {
        document.querySelector('.content').classList.remove('on');
        document.querySelector('.sidebar').classList.remove('on');
      }
    </script>
    <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i>请我喝杯咖啡吧~</p>
  <div class="reward-box">
    
    <div class="reward-item">
      <img class="reward-img" src="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/img/alipay.jpg">
      <span class="reward-type">支付宝</span>
    </div>
    
    
    <div class="reward-item">
      <img class="reward-img" src="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/img/wechat.jpg">
      <span class="reward-type">微信</span>
    </div>
    
  </div>
</div>
    
<script src="/js/jquery-2.0.3.min.js"></script>


<script src="/js/lazyload.min.js"></script>

<!-- Tocbot -->


<script src="/js/tocbot.min.js"></script>

<script>
  tocbot.init({
    tocSelector: '.tocbot',
    contentSelector: '.article-entry',
    headingSelector: 'h1, h2, h3, h4, h5, h6',
    hasInnerContainers: true,
    scrollSmooth: true,
    scrollContainer: 'main',
    positionFixedSelector: '.tocbot',
    positionFixedClass: 'is-position-fixed',
    fixedSidebarOffset: 'auto'
  });
</script>

<script src="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.js"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.css">
<script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js"></script>

<script src="/dist/main.js"></script>

<!-- ImageViewer -->

<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css">
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"></script>

<script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // slider展开状态
                // todo: 这样不好，后面改成状态
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // 获得原图尺寸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script>

<!-- MathJax -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
      tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
  });

  MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for(i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
      }
  });
</script>

<script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.6/unpacked/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
  var ayerConfig = {
    mathjax: true
  }
</script>

<!-- Katex -->

<!-- busuanzi  -->


<script src="/js/busuanzi-2.3.pure.min.js"></script>


<!-- ClickLove -->

<!-- ClickBoom1 -->

<!-- ClickBoom2 -->


<script src="/js/clickBoom2.js"></script>


<!-- CodeCopy -->


<link rel="stylesheet" href="/css/clipboard.css">

<script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>
<script>
  function wait(callback, seconds) {
    var timelag = null;
    timelag = window.setTimeout(callback, seconds);
  }
  !function (e, t, a) {
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '<i class="ri-file-copy-2-line"></i><span>COPY</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      $(".article pre code").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        let $btn = $(e.trigger);
        $btn.addClass('copied');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-checkbox-circle-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPIED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-checkbox-circle-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
      clipboard.on('error', function(e) {
        e.clearSelection();
        let $btn = $(e.trigger);
        $btn.addClass('copy-failed');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-time-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPY FAILED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-time-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
    }
    initCopyCode();
  }(window, document);
</script>


<!-- CanvasBackground -->


<script src="/js/dz.js"></script>



    
  </div>
<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"model":{"jsonPath":"live2d-widget-model-haruto"},"display":{"position":"left","width":150,"height":300},"mobile":{"show":false},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>